{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ClassesAutoEncoder.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyNAX40RwyqdbqYzYLTQpQRU"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "HlEJLM_rsu2t",
    "colab_type": "code",
    "outputId": "f76b92d2-2f25-4520-e5cd-b128f5c1e36f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581249809394,
     "user_tz": -120,
     "elapsed": 4496,
     "user": {
      "displayName": "Bar Cohen",
      "photoUrl": "",
      "userId": "08466736935148352038"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "import time\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import pandas as pd\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uffZ2_dTs7KF",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "class SimpleConvAutoEncoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleConvAutoEncoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, keyrnel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Dense(10),\n",
    "            ]\n",
    "        )\n",
    "            \n",
    "        \n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(10,)),\n",
    "                tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape(target_shape=(7,7,32)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=64,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2,2),\n",
    "                    padding = 'SAME',\n",
    "                    activation='relu'\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=32,\n",
    "                    kernel_size=3,\n",
    "                    strides=(2, 2),\n",
    "                    padding='SAME',\n",
    "                    activation='relu'\n",
    "                ),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1,\n",
    "                    kernel_size=3,\n",
    "                    strides=(1, 1),\n",
    "                    padding='SAME',\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "    def Encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def Decode(self, x):\n",
    "        logits = self.decoder(x)\n",
    "        return tf.sigmoid(logits)\n",
    "    \n",
    "    def custom_save_model(self):\n",
    "      print('saving model..')\n",
    "      self.encoder.save_weights('drive/My Drive/Colab Notebooks/encoder_model.h5')\n",
    "      self.decoder.save_weights('drive/My Drive/Colab Notebooks/decoder_model.h5')\n",
    "\n",
    "    def custom_load_model(self):\n",
    "      print('loading model..')\n",
    "      self.encoder.load_weights('drive/My Drive/Colab Notebooks/encoder_model.h5')\n",
    "      self.decoder.load_weights('drive/My Drive/Colab Notebooks/decoder_model.h5')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t84ywdaEtQHp",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  predictions = model.Decode(test_input)\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  # tight_layout minimizes the overlap between 2 sub-plots\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aFwihyhDtODs",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "def train_and_save_results(model, train_set, test_set):\n",
    "    epochs = 100\n",
    "    optimizer =tf.keras.optimizers.Adam()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        for train_x in train_set:\n",
    "            print(np.sum(compute_loss(model, train_x)))\n",
    "            compute_apply_gradients(model, train_x, optimizer)\n",
    "        end_time = time.time()\n",
    "        loss = np.inf\n",
    "        if epoch:\n",
    "            for test_x in test_set:\n",
    "                loss = np.sum(compute_loss(model, test_x))\n",
    "            display.clear_output(wait=False)\n",
    "            print('Epoch: {}, Test set ELBO: {}, '\n",
    "                  'time elapse for current epoch {}'.format(epoch,\n",
    "                                                            loss,\n",
    "                                                            end_time - start_time))\n",
    "            \n",
    "            model.custom_save_model()\n",
    "            if not (epoch % 10) or epoch == 1: \n",
    "                generate_and_save_images(model, epoch, random_vector_for_generation)\n",
    "                train_dataset, test_dataset, train_labels = load_data(1)\n",
    "                create_2d_plot(train_dataset, train_labels)\n",
    "                # plot_pca(df)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "NS2GWywBbAWo",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jHqPMnCEtJLm",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "@tf.function\n",
    "def compute_loss(model : SimpleConvAutoEncoder,x_real):\n",
    "    z = model.Encode(x_real)\n",
    "    logits = model.decoder(z)\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=x_real)\n",
    "    return tf.reduce_mean(loss)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MKpIA1zOtG0Q",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "@tf.function\n",
    "def compute_apply_gradients(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VvYzdJJ4s_Tf",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "\n",
    "def load_data(batch_size):\n",
    "    TRAIN_BUF = 60000\n",
    "    BATCH_SIZE = batch_size\n",
    "    TEST_BUF = 10000\n",
    "    (train_images, train_labels), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
    "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "    test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "    # Normalizing the images to the range of [0., 1.]\n",
    "    train_images /= 255.\n",
    "    test_images /= 255.\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE)\n",
    "    train_labels = tf.data.Dataset.from_tensor_slices(train_labels).batch(BATCH_SIZE)    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test_images).batch(BATCH_SIZE)\n",
    "    \n",
    "    #train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "    #train_labels = tf.data.Dataset.from_tensor_slices(train_images).shuffle(TRAIN_BUF).batch(BATCH_SIZE)    \n",
    "    #test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(TEST_BUF).batch(BATCH_SIZE)\n",
    "    return train_dataset ,test_dataset , train_labels"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3hjwHjntspzB",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "def plot_pca(df):\n",
    "  fig = plt.figure(figsize = (8,8))\n",
    "  ax = fig.add_subplot(1,1,1) \n",
    "  ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "  ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "  ax.set_title('2 component PCA', fontsize = 20)\n",
    "  ax.scatter(df['pc1'], df['pc2'])\n",
    "  # targets = set(df['target'].values)\n",
    "  # colors = {'b', 'g', 'r', 'c', 'm', 'y', 'k', 'w', 0.2 , 0.8}\n",
    "  # for target, color in zip(targets,colors):\n",
    "      # indicesToKeep = df['target'] == target\n",
    "      # ax.scatter(df.loc[indicesToKeep, 'principal component 1']\n",
    "                # , df.loc[indicesToKeep, 'principal component 2']\n",
    "                # , c = color\n",
    "                # , s = 50)\n",
    "  # ax.legend(targets)\n",
    "  ax.grid()\n",
    "  plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZR47HslR3ZC5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "outputId": "209bdb05-e2e9-4362-b6fb-ec283995cab0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1581249809414,
     "user_tz": -120,
     "elapsed": 4431,
     "user": {
      "displayName": "Bar Cohen",
      "photoUrl": "",
      "userId": "08466736935148352038"
     }
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "At5Cx27jv63G",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "def create_2d_plot(train_dataset, train_labels):\n",
    "  model = SimpleConvAutoEncoder()\n",
    "  model.custom_load_model()\n",
    "  print('creating encoded set')\n",
    "  sample = np.random.sample((500,10))\n",
    "  train_dataset = train_dataset.from_tensor_slices(sample)\n",
    "  train_labels = train_labels.from_tensor_slices(sample)\n",
    "  zs = [model.Encode(z)[0] for z in train_dataset]  \n",
    "  arr = np.array(zs)\n",
    "  # print(zs[0])\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  # X = StandardScaler().fit_transform(arr)\n",
    "  from sklearn.decomposition import PCA\n",
    "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "  from yellowbrick.text import TSNEVisualizer\n",
    "\n",
    "  print('creating and transforming tsne')\n",
    "  labels = ['0 num', '1 num', '2 num ', '3 num', '4 num ', '5 num ', '6 num ', '7 num', '8 num','9 num']\n",
    "  tsne = TSNEVisualizer(decompose_by=5, labels= labels)\n",
    "  train_labels = [l.numpy()[0] for l in train_labels]\n",
    "  tsne.fit(zs, train_labels)\n",
    "  tsne.finalize()\n",
    "  # pca = PCA(n_components=2)\n",
    "  # pcs = pca.fit_transform(arr)\n",
    "\n",
    "  print('creating df')\n",
    "  # principalDf = pd.DataFrame(data = pcs\n",
    "            #  , columns = ['pc1', 'pc2'])\n",
    "  # print('concating df')\n",
    "  # principalDf['target'] = train_labels\n",
    "  # return principalDf\n",
    "\n",
    "  \n",
    "  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j1i28suMtRrz",
    "colab_type": "code",
    "outputId": "4e6c3629-5afb-433c-c283-299aff0e5912",
    "executionInfo": {
     "status": "error",
     "timestamp": 1581250982986,
     "user_tz": -120,
     "elapsed": 1030976,
     "user": {
      "displayName": "Bar Cohen",
      "photoUrl": "",
      "userId": "08466736935148352038"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "\n",
    "tf.enable_eager_execution()\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[16, 10])\n",
    "print(tf.version)\n",
    "model = SimpleConvAutoEncoder()\n",
    "model.custom_load_model()\n",
    "train_dataset, test_dataset, train_labels = load_data(100)\n",
    "train_and_save_results(model, train_dataset, test_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "adK4pvC6gGIA",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXThhCbrknAG",
    "colab_type": "text"
   },
   "source": [
    "# New Section"
   ]
  }
 ]
}